@article{WEI2012316,
title = {Group coordinate descent algorithms for nonconvex penalized regression},
journal = {Computational Statistics & Data Analysis},
volume = {56},
number = {2},
pages = {316-326},
year = {2012},
issn = {0167-9473},
doi = {https://doi.org/10.1016/j.csda.2011.08.007},
url = {https://www.sciencedirect.com/science/article/pii/S0167947311003069},
author = {Fengrong Wei and Hongxiao Zhu},
keywords = {Group coordinate decent algorithm, Grouping structure, High dimension, Minimax concave penalty, Smoothly clipped absolute deviation penalty},
abstract = {We consider the problem of selecting grouped variables in linear regression and generalized linear regression models, based on penalized likelihood. A number of penalty functions have been used for this purpose, including the smoothly clipped absolute deviation (SCAD) penalty and the minimax concave penalty (MCP). These penalty functions, in comparison to the popularly used Lasso, have attractive theoretical properties such as unbiasedness and selection consistency. Although the model fitting methods using these penalties are well developed for individual variable selection, the extension to grouped variable selection is not straightforward, and the fitting can be unstable due to the nonconvexity of the penalty functions. To this end, we propose the group coordinate descent (GCD) algorithms, which extend the regular coordinate descent algorithms. These GCD algorithms are efficient, in that the computation burden only increases linearly with the number of the covariate groups. We also show that using the GCD algorithm, the estimated parameters converge to a global minimum when the sample size is larger than the dimension of the covariates, and converge to a local minimum otherwise. In addition, we demonstrate the regions of the parameter space in which the objective function is locally convex, even though the penalty is nonconvex. In addition to group selection in the linear model, the GCD algorithms can also be extended to generalized linear regression. We present details of the extension using an example of logistic regression. The efficiency of the proposed algorithms are presented through simulation studies and a real data example, in which the MCP based and SCAD based GCD algorithms provide improved group selection results as compared to the group Lasso.}
}